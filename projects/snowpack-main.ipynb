{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "clean = pd.read_csv('snowpack-clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting trends\n",
    "utah = clean.query(\"state == 'UT'\")\n",
    "mostData = clean.query(\"state == 'WA' | state == 'CA' | state == 'AK'\")\n",
    "del clean\n",
    "mostData = utah[utah.id.isin(np.unique(utah.id)[:10])] \n",
    "hasSnow = mostData.query('snow > 0')\n",
    "del utah\n",
    "del mostData\n",
    "\n",
    "# Group data into winters (i.e. periods of continuous snow coverage)\n",
    "# Filter all non-zero values and then group by consecutive index (and site ID)\n",
    "# About 54% of data is nonzero snow\n",
    "hasSnow = mostData.query('snow > 0')\n",
    "hasSnow.reset_index(level=0, inplace=True)\n",
    "hasSnow.rename(columns={'index': 'entry'}, inplace=True)\n",
    "hasSnow.loc[max(hasSnow.index)+1, :] = None\n",
    "hasSnow = hasSnow.assign(entry_s = hasSnow.entry.shift(-1))\n",
    "hasSnow = hasSnow[1:-1] # Remove the NaN rows from shifting\n",
    "hasSnow = hasSnow.assign(consec = (hasSnow.entry + 1) == hasSnow.entry_s) \n",
    "\n",
    "# Determine streaks of greater than 30 consecutive days\n",
    "gaps = np.array(np.where(hasSnow.consec == False))\n",
    "gaps = np.append(np.array([0]), gaps)\n",
    "streaks = np.diff(gaps)\n",
    "winters = [(g+1, g+s, s)  for g,s in zip(gaps, streaks) if s > 30] # start index, end index, and length for each streak\n",
    "winters[0] = (0, winters[0][1], winters[0][2]) # manually start from 0 index (instead of 1)\n",
    "iWinter = np.concatenate([np.repeat(i, w[2]) for i,w in zip(np.arange(1, len(winters) + 1), winters)]) # repeat winter ID for the length of streak\n",
    "\n",
    "keep = np.concatenate([np.arange(i[0], i[1], 1) for i in winters]) \n",
    "hasSnow = hasSnow[hasSnow.index.isin(keep)] \n",
    "hasSnow = hasSnow.assign(winter = iWinter[:-1])\n",
    "smaller = hasSnow[['md', 'id', 'consec']]\n",
    "\n",
    "res = pd.DataFrame(winters)\n",
    "res = res.assign(winter = np.arange(1, len(winters) + 1))\n",
    "res.columns = ['start', 'end', 'days', 'winter']\n",
    "res = pd.merge(res, hasSnow[['winter', 'id', 'state', 'name', 'lat', 'long', 'elev', 'county', 'huc']]).drop_duplicates()\n",
    "# multiple sites for same winter: 10, 20, 31, 43, 86, 117, 100\n",
    "# add length of the winter and max depth\n",
    "\n",
    "hasSnow = hasSnow.assign(plotDate = np.where(hasSnow.month < 9, \n",
    "                                             pd.to_datetime('1971-' + hasSnow.md.map(str), errors='coerce'),\n",
    "                                             pd.to_datetime('1970-' + hasSnow.md.map(str), errors='coerce')))\n",
    "hasSnow = hasSnow[hasSnow.plotDate.notnull()]\n",
    "ggplot(hasSnow, aes('plotDate', 'snow', group = 'winter', color = 'name')) +\\\n",
    "    theme_bw() +\\\n",
    "    geom_line(size = 1.5, alpha = 0.6) +\\\n",
    "    scale_x_date(labels='%b') +\\\n",
    "    xlab('Month') +\\\n",
    "    ylab('Snow Depth (in)')\n",
    "\n",
    " \n",
    "# Filtering\n",
    "    # Remove incomplete winters\n",
    "    # Check spikes > 100 feet (Holts-Winters, exponential smoothing, ARIMA)\n",
    "# Extract the max depth and first melt date for each season\n",
    "# Calculate length/depth ratio\n",
    "# Add meta data into the new data frame version\n",
    "# Get KG climate zone for each (long, lat) location from R\n",
    "# PCA on shape of snow curves?\n",
    "# Overlay temperature plot with snow to look for rapid fall off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
